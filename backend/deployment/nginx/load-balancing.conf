# Advanced Load Balancing Configuration for Multilingual Mandi
# This file provides additional load balancing configurations and strategies
# Requirements: 24.5 - Load balancing across multiple servers for high availability

# ============================================================================
# LOAD BALANCING STRATEGIES
# ============================================================================

# Strategy 1: Least Connections (Default - Best for voice processing)
# Routes requests to the server with the fewest active connections
# Ideal for long-running requests like voice-to-voice translation
upstream backend_least_conn {
    least_conn;
    
    server backend:8000 max_fails=3 fail_timeout=30s weight=1;
    server backend-2:8000 max_fails=3 fail_timeout=30s weight=1;
    server backend-3:8000 max_fails=3 fail_timeout=30s weight=1;
    
    keepalive 64;
    keepalive_requests 100;
    keepalive_timeout 60s;
}

# Strategy 2: IP Hash (Session Persistence)
# Routes requests from the same client IP to the same backend server
# Useful for maintaining session state or WebSocket connections
upstream backend_ip_hash {
    ip_hash;
    
    server backend:8000 max_fails=3 fail_timeout=30s;
    server backend-2:8000 max_fails=3 fail_timeout=30s;
    server backend-3:8000 max_fails=3 fail_timeout=30s;
    
    keepalive 64;
}

# Strategy 3: Round Robin with Weights
# Distributes requests in round-robin fashion with weighted distribution
# Higher weight = more requests (useful for servers with different capacities)
upstream backend_weighted {
    server backend:8000 max_fails=3 fail_timeout=30s weight=3;
    server backend-2:8000 max_fails=3 fail_timeout=30s weight=2;
    server backend-3:8000 max_fails=3 fail_timeout=30s weight=1;
    
    keepalive 64;
}

# Strategy 4: Backup Server Configuration
# Primary servers handle traffic, backup only used when primaries are down
upstream backend_with_backup {
    server backend:8000 max_fails=3 fail_timeout=30s;
    server backend-2:8000 max_fails=3 fail_timeout=30s;
    server backend-3:8000 backup;  # Only used when others fail
    
    keepalive 64;
}

# ============================================================================
# HEALTH CHECK CONFIGURATION
# ============================================================================

# Active health checks require nginx-plus or custom module
# For open-source nginx, we rely on passive health checks via max_fails

# Passive health check parameters:
# - max_fails: Number of failed attempts before marking server as down (default: 1)
# - fail_timeout: Time to wait before retrying a failed server (default: 10s)
# - slow_start: Gradually increase traffic to recovered server (nginx-plus only)

# Example with aggressive health checking:
upstream backend_strict_health {
    least_conn;
    
    # Strict health check: mark down after 2 failures, retry after 60s
    server backend:8000 max_fails=2 fail_timeout=60s;
    server backend-2:8000 max_fails=2 fail_timeout=60s;
    server backend-3:8000 max_fails=2 fail_timeout=60s;
    
    keepalive 64;
}

# ============================================================================
# GEOGRAPHIC/ZONE-BASED LOAD BALANCING
# ============================================================================

# For multi-region deployments, route traffic to nearest data center
# This example shows how to configure multiple upstream groups

# India North Region (Delhi, Punjab, Haryana)
upstream backend_north {
    least_conn;
    server backend-north-1:8000 max_fails=3 fail_timeout=30s;
    server backend-north-2:8000 max_fails=3 fail_timeout=30s;
    keepalive 32;
}

# India South Region (Karnataka, Tamil Nadu, Andhra Pradesh)
upstream backend_south {
    least_conn;
    server backend-south-1:8000 max_fails=3 fail_timeout=30s;
    server backend-south-2:8000 max_fails=3 fail_timeout=30s;
    keepalive 32;
}

# India West Region (Maharashtra, Gujarat)
upstream backend_west {
    least_conn;
    server backend-west-1:8000 max_fails=3 fail_timeout=30s;
    server backend-west-2:8000 max_fails=3 fail_timeout=30s;
    keepalive 32;
}

# India East Region (West Bengal, Odisha)
upstream backend_east {
    least_conn;
    server backend-east-1:8000 max_fails=3 fail_timeout=30s;
    server backend-east-2:8000 max_fails=3 fail_timeout=30s;
    keepalive 32;
}

# ============================================================================
# SERVICE-SPECIFIC LOAD BALANCING
# ============================================================================

# Separate upstream groups for different services
# Allows independent scaling of different components

# Voice processing services (STT, TTS, Translation)
upstream voice_processing {
    least_conn;
    server voice-backend-1:8000 max_fails=3 fail_timeout=30s;
    server voice-backend-2:8000 max_fails=3 fail_timeout=30s;
    server voice-backend-3:8000 max_fails=3 fail_timeout=30s;
    keepalive 64;
}

# Price oracle services
upstream price_oracle {
    least_conn;
    server price-backend-1:8000 max_fails=3 fail_timeout=30s;
    server price-backend-2:8000 max_fails=3 fail_timeout=30s;
    keepalive 32;
}

# Negotiation bot services (LLM-based)
upstream negotiation_bot {
    least_conn;
    server bot-backend-1:8000 max_fails=3 fail_timeout=30s;
    server bot-backend-2:8000 max_fails=3 fail_timeout=30s;
    keepalive 32;
}

# ============================================================================
# LOAD BALANCING BEST PRACTICES
# ============================================================================

# 1. Connection Limits
# Limit concurrent connections per backend to prevent overload
# Requires nginx-plus or limit_conn module

# 2. Request Rate Limiting
# Prevent abuse and ensure fair resource distribution
# Example configuration (add to server block):
#
# limit_req_zone $binary_remote_addr zone=api_limit:10m rate=10r/s;
# limit_req zone=api_limit burst=20 nodelay;

# 3. Slow Start (nginx-plus only)
# Gradually increase traffic to recovered servers
# server backend:8000 slow_start=30s;

# 4. Connection Draining
# Gracefully remove servers from rotation
# Mark server as "down" to stop new connections while allowing existing to complete
# server backend:8000 down;

# 5. Monitoring and Metrics
# Enable stub_status for basic metrics
# Add to server block:
#
# location /nginx_status {
#     stub_status;
#     allow 127.0.0.1;
#     deny all;
# }

# ============================================================================
# FAILOVER CONFIGURATION
# ============================================================================

# Automatic failover with proxy_next_upstream
# Add to location block:
#
# proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504;
# proxy_next_upstream_tries 3;
# proxy_next_upstream_timeout 10s;

# This ensures requests are retried on different backend servers if one fails

# ============================================================================
# NOTES
# ============================================================================

# To use these configurations:
# 1. Include this file in your main nginx.conf or site config
# 2. Reference the desired upstream in your location blocks
# 3. Adjust server addresses and ports to match your deployment
# 4. Monitor backend health and adjust max_fails/fail_timeout as needed
# 5. Consider nginx-plus for advanced features like active health checks

# Performance tuning:
# - Increase keepalive connections for high-traffic scenarios
# - Adjust worker_processes and worker_connections in main nginx.conf
# - Enable gzip compression for text responses
# - Use proxy_cache for cacheable responses

# Security considerations:
# - Always use TLS 1.3 for external connections
# - Implement rate limiting to prevent abuse
# - Use firewall rules to restrict backend access
# - Monitor for unusual traffic patterns
